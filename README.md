# Step by step Transformer implementation using huggingface candle

This is a step by step implementation of the transformer from paper ["Attention Is All You Need"](https://arxiv.org/abs/1706.03762) using the rust programming language and the huggingface candle library.

## Dot Product Attention

!["Image Dot Product Attention](/images/dot-product-attention.png)

## Multi Head Attention

!["Image Multi Head Attention](/images/multi-head-attention.png)

## Transformer

!["Image Transformer](/images/transformer.png)
